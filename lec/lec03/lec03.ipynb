{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/stoic-yang/CS189/blob/main/lec/lec03/lec03.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "editable": true,
        "tags": [],
        "id": "_RkNG-foTz25"
      },
      "source": [
        "<link rel=\"stylesheet\" href=\"berkeley.css\">\n",
        "\n",
        "<h1 class=\"cal cal-h1\">Lecture 03 â€“ CS 189, Fall 2025</h1>\n",
        "\n",
        "In this lecture, we will cover the basic machine learning lifecycle using a hands-on approach with scikit-learn.\n",
        "We will work through each stage of the machine learning lifecycle while also introducing standard machine learning tools and techniques.  The machine learning lifecycle consists of four parts:\n",
        "\n",
        "<div style=\"text-align: center;\">\n",
        "<img src=\"https://eecs189.org/fa25/resources/assets/lectures/lec03/images/ml_lifecycle.png\" alt=\"drawing\" width=\"600\"/>\n",
        "</div>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "JV2yB3IUTz28"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import plotly.express as px"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2azRyIwITz29"
      },
      "source": [
        "<link rel=\"stylesheet\" href=\"berkeley.css\">\n",
        "\n",
        "<h2 class=\"cal cal-h2\">The Learning Problem</h2>\n",
        "\n",
        "Suppose we are launching a new fashion trading website where people can upload pictures of clothing they want to trade. We want to help posters identify the clothing in the images. Suppose we have some training data consisting of clothing pictures with labels describing the type of clothing (e.g., \"dress\", \"shirt\", \"pants\").\n",
        "\n",
        "**What data do we have?**\n",
        "* Labeled training examples.\n",
        "\n",
        "**What do we want to predict?**\n",
        "* The category label of the clothing in the images.  We may want to predict other things as well.\n",
        "\n",
        "**How would we evaluate success?**\n",
        "* We likely want to measure our prediction accuracy.\n",
        "* We may eventually want to improve accuracy on certain high-value classes.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i082ub2MTz2-"
      },
      "source": [
        "<link rel=\"stylesheet\" href=\"berkeley.css\">\n",
        "\n",
        "<h3 class=\"cal cal-h3\">Looking at the Data</h3>\n",
        "\n",
        "A key step that is often overlooked in machine learning projects is understanding the data. This includes exploring the dataset, visualizing the data, and gaining insights into its structure and characteristics.\n",
        "\n",
        "We will be using the Fashion-MNIST dataset, which is a (now) classic dataset with gray scale 28x28 images of articles of clothing.\n",
        "\n",
        ">[Fashion-MNIST: a Novel Image Dataset for Benchmarking Machine Learning Algorithms.](https://arxiv.org/abs/1708.07747) Han Xiao, Kashif Rasul, Roland Vollgraf.\n",
        "> https://github.com/zalandoresearch/fashion-mnist\n",
        "\n",
        "This is an alternative to the even more classic MNIST digits dataset, which contains images of handwritten digits."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BjtbRwyITz2-"
      },
      "source": [
        "The following block of code will download the Fashion-MNIST dataset and load it into memory."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3HHph66YTz2-"
      },
      "outputs": [],
      "source": [
        "# Fetch the Data\n",
        "import torchvision\n",
        "data = torchvision.datasets.FashionMNIST(root='data', train=True, download=True)\n",
        "\n",
        "# Preprocess the data into numpy arrays\n",
        "images = data.data.numpy().astype(float)\n",
        "targets = data.targets.numpy() # integer encoding of class labels\n",
        "class_dict = {i:class_name for i,class_name in enumerate(data.classes)}\n",
        "labels = np.array([class_dict[t] for t in targets]) # raw class labels\n",
        "n = len(images)\n",
        "\n",
        "print(\"Loaded FashionMNIST dataset with {} samples.\".format(n))\n",
        "print(\"Classes: {}\".format(class_dict))\n",
        "print(\"Image shape: {}\".format(images[0].shape))\n",
        "print(\"Image dtype: {}\".format(images[0].dtype))\n",
        "print(\"Image 0:\\n\", images[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9iDs2FFrTz2-"
      },
      "source": [
        "<link rel=\"stylesheet\" href=\"berkeley.css\">\n",
        "\n",
        "\n",
        "<h4 class=\"cal cal-h4\">Understanding The Raw Features (Images)</h4>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V5fNMO0ITz2-"
      },
      "source": [
        "How much data do we have?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LodI6jYwTz2_"
      },
      "outputs": [],
      "source": [
        "images.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UqBh-eSGTz2_"
      },
      "source": [
        "The images are stored in a 60000 by 28 by 28 tensor.  This means we have 60000 images, each of which is 28 pixels wide and 28 pixels tall.  Each pixel is represented by a single value.  What are those values?\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "brnBLsffTz2_"
      },
      "outputs": [],
      "source": [
        "counts, bins =  np.histogram(images, bins=255)\n",
        "fig_pixels = px.bar(x=bins[1:], y=counts,  title=\"Pixel value distribution\",\n",
        "       log_y=True, labels={\"x\":\"Pixel value\", \"y\":\"Count\"})\n",
        "fig_pixels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hwdC5m8bTz2_"
      },
      "source": [
        "It is important to learn how to visualize and work with data.  Here we use Plotly express to visualize the image. Note, I am using the 'gray_r' color map to visualize the images, which is a gray scale color map that is reversed (so that black is 1 and white is 0)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O7LHY2r5Tz2_"
      },
      "outputs": [],
      "source": [
        "px.imshow(images[0], color_continuous_scale='gray_r')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QDeKY4AnTz2_"
      },
      "source": [
        "The following snippet of code visualizes multiple images in a grid.  You are not required to understand this code, but it is useful to know how to visualize images in Python.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9DmaQdLYTz2_"
      },
      "outputs": [],
      "source": [
        "def show_images(images, max_images=40, ncols=5, labels = None):\n",
        "    \"\"\"Visualize a subset of images from the dataset.\n",
        "    Args:\n",
        "        images (np.ndarray): Array of images to visualize [img,row,col].\n",
        "        max_images (int): Maximum number of images to display.\n",
        "        ncols (int): Number of columns in the grid.\n",
        "        labels (np.ndarray, optional): Labels for the images, used for facet titles.\n",
        "    Returns:\n",
        "        plotly.graph_objects.Figure: A Plotly figure object containing the images.\n",
        "    \"\"\"\n",
        "    n = min(images.shape[0], max_images) # number of images to show\n",
        "    px_height = 220 # height of each image in pixels\n",
        "    fig = px.imshow(images[:n, :, :], color_continuous_scale='gray_r',\n",
        "                    facet_col = 0, facet_col_wrap=ncols,\n",
        "                    height = px_height * int(np.ceil(n/ncols)))\n",
        "    fig.update_layout(coloraxis_showscale=False)\n",
        "    if labels is not None:\n",
        "        # Extract the facet number and replace with the label.\n",
        "        fig.for_each_annotation(lambda a: a.update(text=labels[int(a.text.split(\"=\")[-1])]))\n",
        "    return fig"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L3GUcuE6Tz2_"
      },
      "outputs": [],
      "source": [
        "show_images(images, 20, labels=labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pb1J9e4hTz2_"
      },
      "source": [
        "Let's look at a few examples of each class. Here we use Pandas to group images by their labels and sample 2 for each class. You are not required to know Pandas (we won't test you on it), but it is a useful library for data manipulation and analysis and we will use it often in this course."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qjvN4eDiTz3A"
      },
      "outputs": [],
      "source": [
        "idx = (\n",
        "    pd.DataFrame({\"labels\": labels})\n",
        "      .groupby(\"labels\", as_index=False)\n",
        "      .sample(2)\n",
        "      .index\n",
        "      .to_numpy())\n",
        "show_images(images[idx,:,:], labels=labels[idx])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jIn45OVHTz3A"
      },
      "source": [
        "<link rel=\"stylesheet\" href=\"berkeley.css\">\n",
        "\n",
        "\n",
        "<h4 class=\"cal cal-h4\">Understanding the Labels</h4>\n",
        "\n",
        "New let's examine the labels.  Are they discrete?  What is the distribution? Are there missing values or errors?\n",
        "\n",
        "In the Fashion-MNIST dataset, each image is labeled with a class corresponding to a type of clothing. There are 10 classes in total.\n",
        "\n",
        "However, it is also important to understand the distribution of labels in the dataset. This can help us identify potential issues such as class imbalance, where some classes have significantly more samples than others."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SDd1UdVlTz3A"
      },
      "outputs": [],
      "source": [
        "labels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gXXvDJLHTz3A"
      },
      "source": [
        "The labels are strings (discrete)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vbR_okb0Tz3A"
      },
      "source": [
        "What is the distribution of labels?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yPlJ40EnTz3A"
      },
      "outputs": [],
      "source": [
        "px.histogram(labels, title=\"Label distribution\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f0Xm8F3ZTz3A"
      },
      "source": [
        "There appear to be equal proportion of each type of clothing.  We don't have any missing values since all labels are one of the 10 classes (no blank or \"missing\" label values).\n",
        "\n",
        "Most real world datasets aren't this balanced or clean.  In fact, it's common to see a long tail distribution, where a few classes are very common and many classes are rare.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qIwpqL8ATz3A"
      },
      "source": [
        "<link rel=\"stylesheet\" href=\"berkeley.css\">\n",
        "\n",
        "\n",
        "<h3 class=\"cal cal-h3\">Reviewing the Learning Setting</h3>\n",
        "\n",
        "Having examined the data we can see that we have a large collection of pairs of features and categorical labels (with 10 classes). This is a **supervised learning** problem, where the goal is to learn a mapping from the input features (images) to the output labels (categories). Because the labels are discrete this is a **classification** problem.\n",
        "\n",
        "It is also worth noting that because the input features are images this is also a **computer vision** problem.  This means that when we get to the model development stage, we will need to consider techniques that are specifically designed for multi-class classification and in particular computer vision."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "INQ0BjtJTz3A"
      },
      "source": [
        "<br><br><br>\n",
        "\n",
        "---\n",
        "\n",
        "**Return to Slides**\n",
        "\n",
        "---\n",
        "\n",
        "<br><br><br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JZyw4dESTz3A"
      },
      "source": [
        "<link rel=\"stylesheet\" href=\"berkeley.css\">\n",
        "\n",
        "\n",
        "<h3 class=\"cal cal-h3\">Train-Test-Validation Split</h3>\n",
        "\n",
        "We will split the dataset into a training set, a validation set, and a test set. The training set will be used to train the model, while the validation set will be used to tune the model's hyperparameters. The test set will be used to evaluate the model's performance.\n",
        "\n",
        "Technically, the Fashion-MNIST dataset has a separate test set, but we will demonstrate how to split data in general."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bGGoLAZYTz3A"
      },
      "outputs": [],
      "source": [
        "# use sklearn to construct a train test split\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7YmlpjzoTz3A"
      },
      "outputs": [],
      "source": [
        "# Construct the train - test split\n",
        "images_tr, images_te, labels_tr, labels_te = train_test_split(\n",
        "    images, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Construct the train - validation split\n",
        "images_tr, images_val, labels_tr, labels_val = train_test_split(\n",
        "    images_tr, labels_tr, test_size=0.2, random_state=42)\n",
        "\n",
        "print(\"images_tr shape:\", images_tr.shape)\n",
        "print(\"images_val shape:\", images_val.shape)\n",
        "print(\"images_te shape:\", images_te.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OpDXfcclTz3A"
      },
      "source": [
        "<br><br><br>\n",
        "\n",
        "---\n",
        "\n",
        "**Return to Slides**\n",
        "\n",
        "---\n",
        "\n",
        "<br><br><br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YQ9BVJiPTz3A"
      },
      "source": [
        "<link rel=\"stylesheet\" href=\"berkeley.css\">\n",
        "\n",
        "\n",
        "<h2 class=\"cal cal-h2\"> Model Design </h2>\n",
        "\n",
        "We have already loaded the Fashion-MNIST dataset in the previous section. Now, we will preprocess the data to make it suitable for training a classification model.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EeejJ-JCTz3A"
      },
      "source": [
        "<link rel=\"stylesheet\" href=\"berkeley.css\">\n",
        "\n",
        "\n",
        "<h3 class=\"cal cal-h3\">Feature Engineering</h3>\n",
        "\n",
        "**Feature Engineering** is the process of transforming the raw features into a representation that can be used effectively by machine learning techniques.  This will often involve transforming data into vector representations."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qeoPe9-BTz3A"
      },
      "source": [
        "<h4 class=\"cal cal-h4\">Naive Image Featurization</h4>\n",
        "\n",
        "For this example we are working with low-resolution grayscale image data. Here we adopt a very simple featurization approach -- flatten the image. We will convert the 28x28 pixel images into 784-dimensional vectors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Khe6RdLBTz3B"
      },
      "outputs": [],
      "source": [
        "images_tr.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HNt13wbkTz3B"
      },
      "outputs": [],
      "source": [
        "def flatten(images):\n",
        "    return images.reshape(images.shape[0], -1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SPCzl0sdTz3B"
      },
      "outputs": [],
      "source": [
        "X_tr = flatten(images_tr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MAwVG-_oTz3B"
      },
      "outputs": [],
      "source": [
        "X_tr.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h83klXpnTz3B"
      },
      "source": [
        "<link rel=\"stylesheet\" href=\"berkeley.css\">\n",
        "\n",
        "<h4 class=\"cal cal-h4\">Standardization</h4>\n",
        "\n",
        "Recall that the pixel intensities are from 0 to 255:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5cXKTEJsTz3B"
      },
      "outputs": [],
      "source": [
        "fig_pixels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nLkRqJnMTz3E"
      },
      "source": [
        "Let's standardize the pixel intensities to have zero mean and unit variance.\n",
        "\n",
        "Here we use the sklearn StandardScaler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XHuy7UErTz3E"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# 1. Initialize a StandardScaler object\n",
        "image_scaler = StandardScaler()\n",
        "\n",
        "# 2. Fit the scaler\n",
        "image_scaler.fit(flatten(images_tr))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JJVhp7tpTz3E"
      },
      "source": [
        "What do the mean and variance images tell us about the dataset?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qaPSoTcbTz3E"
      },
      "outputs": [],
      "source": [
        "display(px.imshow(image_scaler.mean_.reshape(28,28),\n",
        "                  color_continuous_scale='gray_r', title=\"Mean image\"))\n",
        "display(px.imshow(image_scaler.var_.reshape(28,28),\n",
        "                  color_continuous_scale='gray_r', title=\"Variance image\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9nlzZ5XtTz3E"
      },
      "source": [
        "Let's create a generic featurization function that we can reuse for different datasets.  Notice that this function uses the image_scaler that we fit to the training data.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wPt9Qb1PTz3E"
      },
      "outputs": [],
      "source": [
        "def featurizer(images):\n",
        "    flattened = flatten(images)\n",
        "    return image_scaler.transform(flattened)\n",
        "\n",
        "X_tr = featurizer(images_tr)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mQ39aZZsTz3E"
      },
      "source": [
        "Our new images look similar to the original images but they have been standardized to have zero mean and unit variance. This should help improve the performance of our machine learning models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6yrZ85-ETz3E"
      },
      "outputs": [],
      "source": [
        "show_images(X_tr.reshape(images_tr.shape), max_images=10, labels=labels_tr)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W81pwp43Tz3E"
      },
      "source": [
        "<link rel=\"stylesheet\" href=\"berkeley.css\">\n",
        "\n",
        "<h4 class=\"cal cal-h4\">One-Hot Encoding</h4>\n",
        "\n",
        "We don't need to one-hot encode the features in this dataset so we will briefly demonstrate on another dataset:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZkOp-tBZTz3E"
      },
      "outputs": [],
      "source": [
        "df = pd.DataFrame({\"color\": [\"red\", \"green\", \"red\", \"blue\", \"blue\", \"yellow\", \"\"]})\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_UX4gg6XTz3E"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "# 1. Initialize a OneHotEncoder object\n",
        "ohe = OneHotEncoder()\n",
        "# 2. Fit the encoder\n",
        "ohe.fit(df[[\"color\"]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c2eSOlr9Tz3F"
      },
      "outputs": [],
      "source": [
        "ohe.categories_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mCaRsILjTz3F"
      },
      "outputs": [],
      "source": [
        "ohe.transform(df[[\"color\"]]).toarray()\n",
        "ohe.categories_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XTN3EVlVTz3F"
      },
      "source": [
        "<link rel=\"stylesheet\" href=\"berkeley.css\">\n",
        "\n",
        "<h4 class=\"cal cal-h4\">Bag of Words</h4>\n",
        "\n",
        "We also don't need the bag-of-words representation for this dataset, but we will demonstrate it briefly using another dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QxTGN7r-Tz3F"
      },
      "outputs": [],
      "source": [
        "df['text'] = [\n",
        "    \"Red is a color.\",\n",
        "    \"Green is for green food.\",\n",
        "    \"Red reminds me of red food.\",\n",
        "    \"Blue is my favorite color!\",\n",
        "    \"Blue is for Cal!\",\n",
        "    \"Yellow is also for Cal!\",\n",
        "    \"I forgot to write something.\"\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lw38Gw_qTz3F"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "# 1. Initialize a CountVectorizer object\n",
        "vectorizer = CountVectorizer()\n",
        "\n",
        "# 2. Fit the vectorizer\n",
        "vectorizer.fit(df[\"text\"])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rQaA7tinTz3F"
      },
      "outputs": [],
      "source": [
        "pd.DataFrame(vectorizer.transform(df[\"text\"]).toarray(),\n",
        "             columns=vectorizer.get_feature_names_out())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_19hcf1XTz3F"
      },
      "source": [
        "<br><br><br>\n",
        "\n",
        "---\n",
        "\n",
        "**Return to Slides**\n",
        "\n",
        "---\n",
        "\n",
        "<br><br><br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B6alRR9JTz3F"
      },
      "source": [
        "\n",
        "\n",
        "<link rel=\"stylesheet\" href=\"berkeley.css\">\n",
        "\n",
        "\n",
        "<h2 class=\"cal cal-h2\">Modeling and Optimization</h2>\n",
        "\n",
        "In this section, we will go through the modeling process. We will focus on developing a classification model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DRQV5OdQTz3F"
      },
      "source": [
        "<link rel=\"stylesheet\" href=\"berkeley.css\">\n",
        "\n",
        "\n",
        "<h3 class=\"cal cal-h3\">Training (Fitting) a Classifier </h3>\n",
        "\n",
        "We will start with the most basic classifier, the logistic regression model, to demonstrate the classification workflow.\n",
        "\n",
        "Logistic regression is a **linear model** that is commonly used for binary and multi-class classification tasks.  It is also a good starting point for understanding more complex deep learning models that will be covered later in the course.\n",
        "\n",
        "Here we use `sklearn` to fit a logistic regression model to the training data. The `LogisticRegression` class from `sklearn.linear_model` is used to create an instance of the model.\n",
        "\n",
        "The `fit` method is called on the model instance, passing in the training data and labels. This trains the model to learn the relationship between the input features (flattened images) and the target labels (clothing categories).  In scikit-learn, the `fit` method is used to train any model on the provided data.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a6tXpoiBTz3F"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "lr_model = LogisticRegression()\n",
        "lr_model.fit(X=X_tr, y=labels_tr)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7trGukKbTz3F"
      },
      "source": [
        "Notice that we get a warning that:\n",
        "```plaintext\n",
        "lbfgs failed to converge after 100 iteration(s) (status=1):\n",
        "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
        "```\n",
        "\n",
        "This warning indicates that the **optimization algorithm** used by the logistic regression model did not converge to a solution within the default number of iterations. This can happen if the model is complex or if the data is not well-scaled.\n",
        "\n",
        "We can change the optimization algorithm used by the logistic regression model. The default algorithm is `lbfgs`, which is a quasi-Newton method. Other options include `newton-cg`, `sag`, and `saga`. Each of these algorithms has its own strengths and weaknesses, and the choice of algorithm can affect the convergence speed and final performance of the model.\n",
        "\n",
        "\n",
        "In this class, we will explore variations of stochastic gradient descent like `saga`. Let's try using the `saga` algorithm instead of `lbfgs` to see if it converges faster.  Here we will also set the `tol` parameter since we don't want to wait.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CHzt5TWzTz3G"
      },
      "outputs": [],
      "source": [
        "lr_model = LogisticRegression(tol=0.05, solver='saga', random_state=42)\n",
        "lr_model.fit(X=X_tr, y=labels_tr)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SU23ABE4Tz3G"
      },
      "source": [
        "<link rel=\"stylesheet\" href=\"berkeley.css\">\n",
        "\n",
        "\n",
        "<h3 class=\"cal cal-h3\">Parameters </h3>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Jc6stMYTz3G"
      },
      "source": [
        "The **parameters** of a model are the internal variables that the model learns during the training process. For example, in logistic regression, the parameters are the weights assigned to each feature. These weights are adjusted during training to minimize the loss function, which measures how well the model's predictions match the actual labels."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zjhOlK5XTz3G"
      },
      "outputs": [],
      "source": [
        "print(\"model.coef_.shape:\", lr_model.coef_.shape)\n",
        "print(\"model.intercept_.shape:\", lr_model.intercept_.shape)\n",
        "print(lr_model.coef_)\n",
        "print(lr_model.intercept_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ayRym-ieTz3G"
      },
      "source": [
        "We can also visualize these coefficients.  This can help us understand which pixels are most important for each class. We will learn more about this model in the future. (You don't have to understand these details now.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v5O51eOHTz3G"
      },
      "outputs": [],
      "source": [
        "coeffs = lr_model.coef_\n",
        "show_images(coeffs.reshape(10, 28, 28), labels=lr_model.classes_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eJWoJuMmTz3G"
      },
      "source": [
        "#### Neural Networks\n",
        "\n",
        "\n",
        "Neural networks are often the model of choice for image classification tasks. They can learn complex patterns in the data and often outperform simpler models like logistic regression. However, they also require the correct architecture and significant training data and computational resources.\n",
        "\n",
        "Here we will try a simple neural network with two hidden layers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iCKVx5nnTz3G"
      },
      "outputs": [],
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "mlp = MLPClassifier(\n",
        "    hidden_layer_sizes=(100, 50),\n",
        "    max_iter=100, tol=1e-3, random_state=42)\n",
        "\n",
        "mlp.fit(X=X_tr, y=labels_tr)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vAeK8Y3QTz3G"
      },
      "source": [
        "<link rel=\"stylesheet\" href=\"berkeley.css\">\n",
        "\n",
        "\n",
        "<h3 class=\"cal cal-h3\">Hyperparameters </h3>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PWHconH_Tz3G"
      },
      "source": [
        "The **hyperparameters** are the arguments that are set before the training process begins. These include the choice of optimization algorithm, the learning rate, and the number of iterations, among others. Hyperparameters are typically tuned using techniques like cross-validation to find the best combination for a given dataset.  \n",
        "\n",
        "Confusingly these hyperparameters are often referred to as \"parameters\" in the context of machine learning libraries like `sklearn`. For example, the `LogisticRegression` class has hyperparameters like `solver`, `C`, and `max_iter` that can be adjusted to improve model performance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_ZG7LbSCTz3G"
      },
      "outputs": [],
      "source": [
        "lr_model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X45JxeG2Tz3G"
      },
      "source": [
        "To evaluate the model we will use the validation dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "veIKUdUZTz3G"
      },
      "outputs": [],
      "source": [
        "X_val = featurizer(images_val)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ej1DSvnNTz3G"
      },
      "source": [
        "Let's try tuning the regularization parameter `C`.  To make this process more illustrative we will work with a smaller subset of the training data (n=1000).  This will allow us to better demonstrate underfitting and overfitting and significantly speed up the training process.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f9ciEn2zTz3G"
      },
      "outputs": [],
      "source": [
        "n_small = 1000\n",
        "X_tr_small = X_tr[:n_small,:]\n",
        "labels_tr_small = labels_tr[:n_small]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OJ_PS6xmTz3H"
      },
      "source": [
        "In practice, we need to be careful when tuning regularization parameters against a sample of the data.  In this case, more regularization is likely needed for smaller datasets to prevent overfitting."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jCFWCTEbTz3H"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import log_loss\n",
        "\n",
        "C_vals = np.logspace(-5, 1, 20)\n",
        "\n",
        "logprob_tr = []\n",
        "logprob_val = []\n",
        "acc_tr = []\n",
        "acc_val = []\n",
        "\n",
        "for C in C_vals:\n",
        "    print(\"starting training with C =\", C)\n",
        "    model = LogisticRegression(tol=1e-3, random_state=42, C=C)\n",
        "    model.fit(X=X_tr_small, y=labels_tr_small)\n",
        "\n",
        "    # compute the logprob accuracy\n",
        "    logprob_tr.append(-log_loss(labels_tr_small, model.predict_proba(X_tr_small), labels=model.classes_))\n",
        "    logprob_val.append(-log_loss(labels_val, model.predict_proba(X_val), labels=model.classes_))\n",
        "\n",
        "    # compute the accuracy\n",
        "    acc_tr.append(np.mean(model.predict(X_tr_small) == labels_tr_small))\n",
        "    acc_val.append(np.mean(model.predict(X_val) == labels_val))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gmfNtoMVTz3H"
      },
      "outputs": [],
      "source": [
        "df_logprob = pd.DataFrame({\n",
        "    \"C_val\": C_vals,\n",
        "    \"Train\": logprob_tr, \"Validation\": logprob_val,\n",
        "}).set_index(\"C_val\")\n",
        "\n",
        "display(\n",
        "    px.line(df_logprob,\n",
        "        labels={\"value\": \"Avg. Log Prob.\", \"C_val\": \"Reg. Parameter C\"},\n",
        "        title=\"LR Classifier Log Prog vs Reg. Parameter\",\n",
        "        markers=True,\n",
        "        log_x=True,\n",
        "        width=800, height=500)\n",
        ")\n",
        "\n",
        "df_acc = pd.DataFrame({\n",
        "    \"C_val\": C_vals,\n",
        "    \"Train\": acc_tr, \"Validation\": acc_val\n",
        "}).set_index(\"C_val\")\n",
        "\n",
        "display(\n",
        "    px.line(df_acc,\n",
        "        labels={\"value\": \"Accuracy\", \"C_val\": \"Reg. Parameter C\"},\n",
        "        title=\"LR Classifier Accuracy vs Reg. Parameter\",\n",
        "        markers=True,\n",
        "        log_x=True,\n",
        "        width=800, height=500\n",
        "    )\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d4cksYX8Tz3H"
      },
      "source": [
        "<link rel=\"stylesheet\" href=\"berkeley.css\">\n",
        "\n",
        "\n",
        "<h2 class=\"cal cal-h2\">Evaluating the Model</h2>\n",
        "\n",
        "After training the model, we can use it to make predictions on new data. The `predict` method of the trained model is used to generate predictions based on the input features."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g7ugg6zcTz3H"
      },
      "source": [
        "Let's return to our logistic regression model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1y0B_bYBTz3H"
      },
      "outputs": [],
      "source": [
        "lr_model.predict(X_tr[:10,:])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Im9IcGyNTz3H"
      },
      "source": [
        "Do you agree with the predictions? Let's visualize the predictions on a few test images."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "THpzWOG8Tz3H"
      },
      "outputs": [],
      "source": [
        "show_images(images_tr[:10,:].reshape(10, 28, 28),\n",
        "            labels = lr_model.predict(X_tr[:10,:]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hkxNLrNYTz3H"
      },
      "source": [
        "Now let's see what the correct labels are for these images."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7WffD5d0Tz3H"
      },
      "outputs": [],
      "source": [
        "k = 10\n",
        "tmp_labels = labels_tr[:k] + \" (pred=\" + lr_model.predict(X_tr[:k,:]) + \")\"\n",
        "show_images(images_tr[:k,:].reshape(k, 28, 28), labels=tmp_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gil2rX7qTz3H"
      },
      "source": [
        "<link rel=\"stylesheet\" href=\"berkeley.css\">\n",
        "\n",
        "\n",
        "<h3 class=\"cal cal-h3\">Predicting Probabilities</h3>\n",
        "\n",
        "Many models can also provide probabilities for each class using the `predict_proba` method. This is useful for understanding the model's confidence in its predictions.  In this class, we will often use a probabilistic framing, where we interpret the output of the model as probabilities of each class."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J1tnFOkYTz3H"
      },
      "outputs": [],
      "source": [
        "lr_model.predict_proba(X_tr[:5,:])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cEw56yL_Tz3H"
      },
      "source": [
        "We can visualize these probabilities for the same images we predicted earlier."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UF12Fm89Tz3H"
      },
      "outputs": [],
      "source": [
        "k = 10\n",
        "df = pd.DataFrame(lr_model.predict_proba(X_tr[:k,:]), columns=lr_model.classes_)\n",
        "bars = px.bar(df, barmode='stack',orientation='v')\n",
        "bars.update_layout(xaxis_tickmode='array', xaxis_tickvals=np.arange(k))\n",
        "display(bars)\n",
        "tmp_labels = labels_tr[:k] + \" (pred=\" + lr_model.predict(X_tr[:k,:]) + \") img: \" + np.arange(k).astype(str)\n",
        "show_images(images_tr[:k,:].reshape(k, 28, 28), labels=tmp_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nVWUWeavTz3H"
      },
      "source": [
        "<link rel=\"stylesheet\" href=\"berkeley.css\">\n",
        "\n",
        "\n",
        "<h3 class=\"cal cal-h3\">Accuracy Metrics and Test Performance</h3>\n",
        "\n",
        "After training the model, we often want to evaluate the model. There are many ways to evaluate a model, and the best method depends on the task and the data. For classification tasks, we often use metrics like accuracy, precision, recall, and F1-score. Let's start with accuracy.\n",
        "\n",
        "Accuracy is the simplest metric, which measures the proportion of correct predictions out of the total number of predictions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pNBo7pmCTz3H"
      },
      "source": [
        "Let's start by computing the accuracy of our model on the training set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rb1FKSoyTz3H"
      },
      "outputs": [],
      "source": [
        "np.mean(lr_model.predict(X_tr) == labels_tr, axis=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YchEHtT4Tz3I"
      },
      "source": [
        "One of the issues with the training set is that the model may have overfit to the training data, meaning it performs well on the training set but poorly on unseen data. Intuitively, this is like practicing on a set of questions and then getting those same questions right on a test, but not being able to answer new questions that are similar but not identical.\n",
        "\n",
        "To assess the model's performance on unseen data, we will evaluate it on the test set. Recall, the test set is a separate portion of the dataset that was not used during training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Set7V8PCTz3I"
      },
      "outputs": [],
      "source": [
        "X_te = featurizer(images_te)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B3_C0LNyTz3I"
      },
      "outputs": [],
      "source": [
        "np.mean(lr_model.predict(X_te) == labels_te, axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lxOTNGgpTz3I"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "train_acc = accuracy_score(labels_tr, lr_model.predict(X_tr))\n",
        "val_acc = accuracy_score(labels_val, lr_model.predict(X_val))\n",
        "test_acc = accuracy_score(labels_te, lr_model.predict(X_te))\n",
        "\n",
        "print(\"Train accuracy:\", train_acc)\n",
        "print(\"Validation accuracy:\", val_acc)\n",
        "print(\"Test accuracy:\", test_acc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4HGkcjWGTz3I"
      },
      "source": [
        "The test accuracy is slightly lower than the training accuracy, which is expected. However, the difference is not too large, indicating that the model has not overfit significantly."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mfxu4UujTz3I"
      },
      "source": [
        "**Is this accuracy good? What would a random guess yield?**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2PQG3MKfTz3I"
      },
      "source": [
        "A common way to evaluate a classification model is to compare its accuracy against a baseline. Perhaps the simplest baseline is random guessing, where we randomly assign a class to each image.\n",
        "\n",
        "**What accuracy does random guessing yield?**\n",
        "\n",
        "This would depend on the how frequently each class appears in the test dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O0zoznP-Tz3I"
      },
      "outputs": [],
      "source": [
        "np.random.seed(42)\n",
        "print(\"Model Accuracy:\", np.mean(lr_model.predict(X_val) == labels_val, axis=0))\n",
        "print(\"Random Guess Accuracy:\",\n",
        "      np.mean(np.random.choice(lr_model.classes_, size=len(labels_te)) == labels_te, axis=0))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vL_1iWD8Tz3I"
      },
      "source": [
        "Does our model struggle with any particular class?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "THpF0P5wTz3I"
      },
      "outputs": [],
      "source": [
        "isWrong = lr_model.predict(X_val) != labels_val\n",
        "# make a histogram with frequency of correct and incorrect predictions\n",
        "fig = px.histogram(labels_val[isWrong], histnorm='percent')\n",
        "fig.update_layout(xaxis_title=\"Label\",\n",
        "                  yaxis_title=\"Percentage of Incorrect Predictions\")\n",
        "fig.update_xaxes(categoryorder=\"total descending\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pPPRiBZ4Tz3I"
      },
      "source": [
        "For classification tasks, we often want to look at more than just accuracy. We can use a confusion matrix to visualize the performance of the model across different classes. The confusion matrix shows the number of correct and incorrect predictions for each class."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w0jlwadQTz3I"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "fig = px.imshow(\n",
        "    confusion_matrix(labels_val, lr_model.predict(X_val)),\n",
        "    color_continuous_scale='Blues'\n",
        "    )\n",
        "fig.update_layout(\n",
        "        xaxis_title=\"Predicted Label\",\n",
        "        yaxis_title=\"True Label\",\n",
        "        coloraxis_showscale=False,\n",
        "        xaxis=dict(tickmode='array', tickvals=np.arange(len(model.classes_)), ticktext=model.classes_),\n",
        "        yaxis=dict(tickmode='array', tickvals=np.arange(len(model.classes_)), ticktext=model.classes_)\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NvMHMV-dTz3I"
      },
      "source": [
        "<link rel=\"stylesheet\" href=\"berkeley.css\">\n",
        "\n",
        "\n",
        "<h2 class=\"cal cal-h2\">Last Thoughts</h2>\n",
        "\n",
        "In the homework, you will have a chance to work with this data and use scikit-learn in more depth.  We recommend reading the documentation and tutorial on the scikit-learn website as we go through the course.  These provide a great resource for understanding the various functions and capabilities of the library as well as machine learning concepts.\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "py_3_11",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.13"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}